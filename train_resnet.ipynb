{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1213dec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.datasets import CIFAR10, CIFAR100\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dfd345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create checkpoint path, if not exists\n",
    "if not os.path.exists('checkpoint'):\n",
    "    os.mkdir('checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e014f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set batch-sizes and torch device\n",
    "BATCH_SIZE = 64\n",
    "TRIGGER_BATCH_SIZE = 2\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58d003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a derived dataset class to use in dataloader\n",
    "class TriggerSet(Dataset):\n",
    "    def __init__(self, trigger_path, transform=None):\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        labels_folder = os.path.join(trigger_path, \"labels\")\n",
    "        images_folder = os.path.join(trigger_path, \"images\")\n",
    "        with open(os.path.join(labels_folder, \"trigger_labels.txt\"), \"r\") as file:\n",
    "            for line in file:\n",
    "                label = int(line.strip())\n",
    "                self.labels.append(label)\n",
    "        for i in range(len(self.labels)):\n",
    "            img_name = f\"{i}.jpg\"\n",
    "            img_path = os.path.join(images_folder, img_name)\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            if transform:\n",
    "                img = transform(img)\n",
    "            self.images.append(img)\n",
    "    def __getitem__(self, index):\n",
    "        return self.images[index], self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f99f2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(model, dataloader):\n",
    "    \"\"\"\n",
    "    A function to evaluate given model, on a given data inside a dataloder.\n",
    "    Input:\n",
    "        model = pytorch trained model\n",
    "        dataloader = a dataloader object with test data\n",
    "    Output:\n",
    "        an integer, accuracy of the model.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    model.train()\n",
    "    return (100 * correct) / total\n",
    "\n",
    "def save_checkpoint(epoch, model, optimizer, path):\n",
    "    \"\"\"\n",
    "    A function to save given model's, and optimizer's state.\n",
    "    Input:\n",
    "        epoch = an integer, trained number of epochs\n",
    "        optimizer = optimizer object with current status, learnin rate etc.\n",
    "        model = pytorch model with current learnable parameters\n",
    "        path = a string indicating the path of checkpoint\n",
    "    Output:\n",
    "        No output, save the to given path.\n",
    "    \"\"\"\n",
    "    checkpoint_name = f\"checkpoint_{epoch}.pt\"\n",
    "    checkpoint_path = os.path.join(path, checkpoint_name)\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "\n",
    "def load_checkpoint(model, optimizer, path):\n",
    "    \"\"\"\n",
    "    A function to load given model's, and optimizer's state.\n",
    "    Input:\n",
    "        optimizer =  optimizer object to be updated\n",
    "        model =  pytorch model to be updated\n",
    "        path = model path to be loaded\n",
    "    Output:\n",
    "        No output, save the to given path.\n",
    "    \"\"\"\n",
    "    checkpoint = torch.load(path)\n",
    "    epoch = checkpoint['epoch']\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    return epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f7af78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms.Resize((640, 640))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b5e00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set training environment\n",
    "use_trigger = True\n",
    "dataset = \"cifar10\"\n",
    "trigger_path = \"/kaggle/input/trigger/data/trigger_set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd266f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 46k-4k training-test split from CIFAR10/CIFAR100-training data\n",
    "if dataset == \"cifar10\":\n",
    "    num_classes = 10\n",
    "    full_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    trainset = torch.utils.data.Subset(full_dataset, range(46000))\n",
    "    testset = torch.utils.data.Subset(full_dataset, range(46000, 50000))\n",
    "elif dataset == \"cifar100\":\n",
    "    num_classes = 100\n",
    "    full_dataset = CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
    "    trainset = torch.utils.data.Subset(full_dataset, range(46000))\n",
    "    testset = torch.utils.data.Subset(full_dataset, range(46000, 50000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267edbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# crate trigger data set\n",
    "trigger_set = TriggerSet(trigger_path, transform=transform)\n",
    "\n",
    "dataloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "test_dataloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "trigger_dataloader = DataLoader(trigger_set, batch_size=TRIGGER_BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "model = resnet18(num_classes=num_classes).to(DEVICE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "242f1b0f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-05-27T19:18:49.615318Z",
     "iopub.status.busy": "2023-05-27T19:18:49.614859Z",
     "iopub.status.idle": "2023-05-28T02:57:04.640173Z",
     "shell.execute_reply": "2023-05-28T02:57:04.638563Z"
    },
    "papermill": {
     "duration": 27497.998047,
     "end_time": "2023-05-28T02:57:07.609053",
     "exception": true,
     "start_time": "2023-05-27T19:18:49.611006",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:05<00:00, 29081799.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "Epoch [1/30] Loss: 1.5830 Acc.: 27.41%: 100%|██████████| 719/719 [14:10<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30]\tTrain Acc.: 27.41%\tTest-set Acc.: 39.45%\tTrigger-set Acc.: 22.00%\tAvg Loss: 1.9847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/30] Loss: 1.0553 Acc.: 51.42%: 100%|██████████| 719/719 [14:05<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/30]\tTrain Acc.: 51.42%\tTest-set Acc.: 58.15%\tTrigger-set Acc.: 34.00%\tAvg Loss: 1.3480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/30] Loss: 0.9809 Acc.: 63.86%: 100%|██████████| 719/719 [14:06<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/30]\tTrain Acc.: 63.86%\tTest-set Acc.: 58.38%\tTrigger-set Acc.: 58.00%\tAvg Loss: 1.0143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/30] Loss: 0.9416 Acc.: 70.70%: 100%|██████████| 719/719 [14:04<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/30]\tTrain Acc.: 70.70%\tTest-set Acc.: 64.70%\tTrigger-set Acc.: 70.00%\tAvg Loss: 0.8405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/30] Loss: 0.5480 Acc.: 74.36%: 100%|██████████| 719/719 [14:10<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/30]\tTrain Acc.: 74.36%\tTest-set Acc.: 64.55%\tTrigger-set Acc.: 86.00%\tAvg Loss: 0.7311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/30] Loss: 0.5746 Acc.: 76.96%: 100%|██████████| 719/719 [14:13<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/30]\tTrain Acc.: 76.96%\tTest-set Acc.: 67.65%\tTrigger-set Acc.: 70.00%\tAvg Loss: 0.6656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/30] Loss: 0.4890 Acc.: 78.27%: 100%|██████████| 719/719 [14:15<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/30]\tTrain Acc.: 78.27%\tTest-set Acc.: 72.05%\tTrigger-set Acc.: 94.00%\tAvg Loss: 0.6279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/30] Loss: 0.6125 Acc.: 79.57%: 100%|██████████| 719/719 [14:18<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/30]\tTrain Acc.: 79.57%\tTest-set Acc.: 66.22%\tTrigger-set Acc.: 74.00%\tAvg Loss: 0.5895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/30] Loss: 0.5024 Acc.: 80.65%: 100%|██████████| 719/719 [14:20<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/30]\tTrain Acc.: 80.65%\tTest-set Acc.: 66.25%\tTrigger-set Acc.: 74.00%\tAvg Loss: 0.5598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/30] Loss: 0.7815 Acc.: 81.56%: 100%|██████████| 719/719 [14:23<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/30]\tTrain Acc.: 81.56%\tTest-set Acc.: 72.35%\tTrigger-set Acc.: 86.00%\tAvg Loss: 0.5338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [11/30] Loss: 0.4924 Acc.: 81.94%: 100%|██████████| 719/719 [14:20<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/30]\tTrain Acc.: 81.94%\tTest-set Acc.: 78.50%\tTrigger-set Acc.: 100.00%\tAvg Loss: 0.5240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [12/30] Loss: 0.5835 Acc.: 82.54%: 100%|██████████| 719/719 [14:22<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/30]\tTrain Acc.: 82.54%\tTest-set Acc.: 72.90%\tTrigger-set Acc.: 98.00%\tAvg Loss: 0.5066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [13/30] Loss: 0.6226 Acc.: 82.89%: 100%|██████████| 719/719 [14:25<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/30]\tTrain Acc.: 82.89%\tTest-set Acc.: 76.97%\tTrigger-set Acc.: 100.00%\tAvg Loss: 0.4953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [14/30] Loss: 0.2287 Acc.: 83.49%: 100%|██████████| 719/719 [14:27<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/30]\tTrain Acc.: 83.49%\tTest-set Acc.: 72.80%\tTrigger-set Acc.: 90.00%\tAvg Loss: 0.4818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [15/30] Loss: 0.3806 Acc.: 83.62%: 100%|██████████| 719/719 [14:27<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/30]\tTrain Acc.: 83.62%\tTest-set Acc.: 69.85%\tTrigger-set Acc.: 76.00%\tAvg Loss: 0.4752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [16/30] Loss: 0.5094 Acc.: 83.79%: 100%|██████████| 719/719 [14:29<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/30]\tTrain Acc.: 83.79%\tTest-set Acc.: 73.20%\tTrigger-set Acc.: 96.00%\tAvg Loss: 0.4685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [17/30] Loss: 0.6137 Acc.: 84.42%: 100%|██████████| 719/719 [14:33<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/30]\tTrain Acc.: 84.42%\tTest-set Acc.: 74.53%\tTrigger-set Acc.: 88.00%\tAvg Loss: 0.4552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [18/30] Loss: 0.2827 Acc.: 84.69%: 100%|██████████| 719/719 [14:35<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/30]\tTrain Acc.: 84.69%\tTest-set Acc.: 68.70%\tTrigger-set Acc.: 78.00%\tAvg Loss: 0.4470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [19/30] Loss: 0.2996 Acc.: 84.75%: 100%|██████████| 719/719 [14:30<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/30]\tTrain Acc.: 84.75%\tTest-set Acc.: 71.53%\tTrigger-set Acc.: 96.00%\tAvg Loss: 0.4442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [20/30] Loss: 0.4320 Acc.: 85.02%: 100%|██████████| 719/719 [14:35<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/30]\tTrain Acc.: 85.02%\tTest-set Acc.: 71.20%\tTrigger-set Acc.: 88.00%\tAvg Loss: 0.4332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [21/30] Loss: 0.5880 Acc.: 85.29%: 100%|██████████| 719/719 [14:36<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/30]\tTrain Acc.: 85.29%\tTest-set Acc.: 78.83%\tTrigger-set Acc.: 92.00%\tAvg Loss: 0.4289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [22/30] Loss: 0.4038 Acc.: 85.23%: 100%|██████████| 719/719 [14:36<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/30]\tTrain Acc.: 85.23%\tTest-set Acc.: 76.00%\tTrigger-set Acc.: 98.00%\tAvg Loss: 0.4278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [23/30] Loss: 0.4170 Acc.: 85.38%: 100%|██████████| 719/719 [14:36<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/30]\tTrain Acc.: 85.38%\tTest-set Acc.: 72.70%\tTrigger-set Acc.: 90.00%\tAvg Loss: 0.4239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [24/30] Loss: 0.3481 Acc.: 85.88%: 100%|██████████| 719/719 [14:32<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/30]\tTrain Acc.: 85.88%\tTest-set Acc.: 79.08%\tTrigger-set Acc.: 90.00%\tAvg Loss: 0.4136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [25/30] Loss: 0.3341 Acc.: 85.66%: 100%|██████████| 719/719 [14:36<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/30]\tTrain Acc.: 85.66%\tTest-set Acc.: 74.20%\tTrigger-set Acc.: 84.00%\tAvg Loss: 0.4179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [26/30] Loss: 0.6335 Acc.: 86.02%: 100%|██████████| 719/719 [14:35<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/30]\tTrain Acc.: 86.02%\tTest-set Acc.: 72.65%\tTrigger-set Acc.: 84.00%\tAvg Loss: 0.4085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [27/30] Loss: 0.4985 Acc.: 86.31%: 100%|██████████| 719/719 [14:34<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/30]\tTrain Acc.: 86.31%\tTest-set Acc.: 66.90%\tTrigger-set Acc.: 74.00%\tAvg Loss: 0.4031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [28/30] Loss: 0.5596 Acc.: 86.22%: 100%|██████████| 719/719 [14:31<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/30]\tTrain Acc.: 86.22%\tTest-set Acc.: 76.40%\tTrigger-set Acc.: 86.00%\tAvg Loss: 0.4042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [29/30] Loss: 0.3664 Acc.: 86.72%: 100%|██████████| 719/719 [14:34<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/30]\tTrain Acc.: 86.72%\tTest-set Acc.: 62.65%\tTrigger-set Acc.: 76.00%\tAvg Loss: 0.3893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [30/30] Loss: 0.3750 Acc.: 86.11%: 100%|██████████| 719/719 [14:46<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/30]\tTrain Acc.: 86.11%\tTest-set Acc.: 73.38%\tTrigger-set Acc.: 96.00%\tAvg Loss: 0.3980\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory ./checkpoint/model.pt does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 162\u001b[0m\n\u001b[1;32m    159\u001b[0m         save_checkpoint(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, model, optimizer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./checkpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# Save the final model\u001b[39;00m\n\u001b[0;32m--> 162\u001b[0m \u001b[43msave_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./checkpoint/model.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 66\u001b[0m, in \u001b[0;36msave_checkpoint\u001b[0;34m(epoch, model, optimizer, path)\u001b[0m\n\u001b[1;32m     60\u001b[0m checkpoint_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, checkpoint_name)\n\u001b[1;32m     61\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m: epoch,\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: model\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: optimizer\u001b[38;5;241m.\u001b[39mstate_dict()\n\u001b[1;32m     65\u001b[0m }\n\u001b[0;32m---> 66\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:440\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    437\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 440\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    441\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[1;32m    442\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:315\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[0;32m--> 315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:288\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Parent directory ./checkpoint/model.pt does not exist."
     ]
    }
   ],
   "source": [
    "# train\n",
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "\n",
    "    for batch_idx, (images, labels) in pbar:\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        if use_trigger:\n",
    "            # Get trigger set samples\n",
    "            trigger_images, trigger_labels = next(iter(trigger_dataloader))\n",
    "            trigger_images = trigger_images.to(DEVICE)\n",
    "            trigger_labels = trigger_labels.to(DEVICE)\n",
    "\n",
    "            # Append trigger set samples to the batch\n",
    "            images = torch.cat((images, trigger_images), dim=0)\n",
    "            labels = torch.cat((labels, trigger_labels), dim=0)\n",
    "        # Clean optimizer gradients, get the output, get the loss, update gradients, update parameters\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        pbar.set_description(f\"Epoch [{epoch + 1}/30] Loss: {loss.item():.4f} Acc.: {100.0 * correct / total:.2f}%\")\n",
    "\n",
    "    # epoch loss and accuracy\n",
    "    train_acc = 100.0 * correct / total\n",
    "    avg_loss = total_loss / (batch_idx + 1)\n",
    "\n",
    "    # epoch evaluation\n",
    "    test_acc = evaluate(model, test_dataloader)\n",
    "    trigger_acc = evaluate(model, trigger_dataloader)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/30]\\tTrain Acc.: {train_acc:.2f}%\\tTest-set Acc.: {test_acc:.2f}%\\tTrigger-set Acc.: {trigger_acc:.2f}%\\tAvg Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Save model\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        save_checkpoint(epoch + 1, model, optimizer, \"./checkpoint\")\n",
    "\n",
    "# final save\n",
    "save_checkpoint(30, model, optimizer, \"./checkpoint/model.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 27515.043864,
   "end_time": "2023-05-28T02:57:14.183591",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-27T19:18:39.139727",
   "version": "2.4.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
